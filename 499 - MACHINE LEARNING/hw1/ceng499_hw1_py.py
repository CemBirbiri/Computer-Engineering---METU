# -*- coding: utf-8 -*-
"""ceng499_hw1.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17bqBua-47CJVNMUrztVDMsTPskPmJxpJ
"""

#from google.colab import drive
#drive.mount("/content/gdrive")

!wget user.ceng.metu.edu.tr/~artun/ceng499/dataset.zip
!unzip dataset.zip

!ls

# Commented out IPython magic to ensure Python compatibility.
from google.colab.patches import cv2_imshow
import numpy as np
import cv2


from skimage.io import imread
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.model_selection import train_test_split

# for evaluating the model
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# PyTorch libraries and modules
import torch
from torch.autograd import Variable
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam, SGD

import torchvision
resize = torchvision.transforms.Resize((32,32))
from PIL import Image

X=[]
# Load an color image in grayscale
for i in range(0,10000):
  img = cv2.imread('data/train/'+str(i)+'.png',1)
  PIL_image = Image.fromarray(img)
  img= resize(PIL_image)
  img= np.array(img)
  X.append(img)


cv2_imshow(X[0])
print(X[0].shape)
print(type(X[0]))
Y=[]
with open('data/train/labels.txt', 'r') as f:
  for line in f:
    linee = line.split(' ')
    Y.append(int(linee[1]))


train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size = 0.20)


# TRAINING dataset
train_X=np.array(train_X, dtype=np.float32)
train_X = train_X.reshape(8000, 3, 32, 32)
train_X = torch.from_numpy(train_X)

#train_Y=np.array(train_Y, dtype=np.int32)
train_Y=np.array(train_Y)
train_Y = train_Y.astype(int);
train_Y = torch.from_numpy(train_Y)
print(type(train_X))
print(type(train_Y))
print("train_X.shape  = ",train_X.shape)
print("train_Y.shape = ",train_Y.shape)

#VALIDATION dataset
val_X = np.array(val_X, dtype=np.float32)
val_X = val_X.reshape(2000, 3, 32, 32)
val_X  = torch.from_numpy(val_X)

val_Y=np.array(val_Y)
#val_Y = np.array(val_Y, dtype=np.int32)
val_Y = val_Y.astype(int);
val_Y= torch.from_numpy(val_Y)
print(type(val_X))
print(type(val_Y))
print("val_X.shape  = ",val_X.shape)
print("val_Y.shape = ",val_Y.shape)

#train_Y = train_Y.reshape(10000, 1, 1, 32)

import torch.nn.functional as F
import torch.nn as nn

class Net(nn.Module):   
    def __init__(self):
        super(Net, self).__init__()

        
        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, stride=1, padding=0)
        self.bn_conv1=nn.BatchNorm2d(6)

        self.conv2= nn.Conv2d(6, 10, kernel_size=3, stride=1, padding=0)
        self.bn_conv2=nn.BatchNorm2d(10)

        self.maxpool= nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.Linear1 = nn.Linear(28 * 28 * 10, 500)
        self.Linear2 = nn.Linear(500, 100)
        
        self.softmax = nn.Softmax(dim=1)
        

    

    # Defining the forward pass    
    def forward(self, x):
        x = F.relu(self.bn_conv1(self.conv1(x)))
        #x = self.maxpool(x)
        x = F.relu(self.bn_conv2(self.conv2(x)))
        #
        #x = self.maxpool(x)

        x = x.view(x.size(0), -1)
        x = F.relu(self.Linear1(x))
        x = F.relu(self.Linear2(x))
        x = self.softmax(x)
        return x

## defining the model
model = Net()
# defining the optimizer
optimizer = Adam(model.parameters(), lr=0.009)
# defining the loss function
criterion = CrossEntropyLoss()
# checking if GPU is available
#if torch.cuda.is_available():
    #model = model.cuda()
    #criterion = criterion.cuda()

torch.manual_seed(1234)

def train(epoch):
    model.train()
    tr_loss = 0
    # getting the training set
    x_train, y_train = Variable(train_X), Variable(train_Y)
    # getting the validation set
    x_val, y_val = Variable(val_X), Variable(val_Y)
    # converting the data into GPU format
    #if torch.cuda.is_available():
        #x_train = x_train.cuda()
        #y_train = y_train.cuda()
        #x_val = x_val.cuda()
        #y_val = y_val.cuda()

    # clearing the Gradients of the model parameters
    optimizer.zero_grad()
    
    # prediction for training and validation set
    output_train = model(x_train)
    output_val = model(x_val)

    # computing the training and validation loss
    loss_train = criterion(output_train, y_train)
    loss_val = criterion(output_val, y_val)
    train_losses.append(loss_train)
    val_losses.append(loss_val)

    # computing the updated weights of all the model parameters
    loss_train.backward()
    optimizer.step()
    tr_loss = loss_train.item()
    if epoch%10 == 0:
        # printing the validation loss
        print('Epoch : ',epoch+1, '\t', 'loss :', loss_val)


# defining the number of epochs
n_epochs = 30
# empty list to store training losses
train_losses = []
# empty list to store validation losses
val_losses = []
# training the model
for epoch in range(n_epochs):
    train(epoch)

import matplotlib.pyplot as plt

# plotting the training and validation loss
plt.plot(train_losses, label='Training loss')
plt.plot(val_losses, label='Validation loss')
plt.legend()
plt.show()

# prediction for training set
with torch.no_grad():
    #output = model(train_X.cuda())
    output = model(train_X)
    
softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)

# accuracy on training set
accuracy_score(train_Y, predictions)

# prediction for validation set
model.eval()
with torch.no_grad():
    #output = model(val_X.cuda())
    output = model(val_X)

softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)


outputs = model(val_X)
_, predicted = torch.max(outputs.data, 1)
# accuracy on validation set
print(accuracy_score(val_Y, predictions))
print(accuracy_score(val_Y, predicted))
print(val_Y[0:10])
print(predicted[0:10])

import numpy as np
import pandas as pd
import torch
from torch.autograd import Variable

model = torch.nn.Sequential(
    torch.nn.Conv2d(3,6,kernel_size=3),
    #torch.nn.BatchNorm2d(6),
    torch.nn.ReLU(),
    torch.nn.MaxPool2d(kernel_size=2, stride=2),
    
    torch.nn.Conv2d(6,16,kernel_size=3),
    #torch.nn.BatchNorm2d(16),
    torch.nn.ReLU(),
    torch.nn.MaxPool2d(kernel_size=2, stride=2)
    
    
    #torch.nn.Linear(16 * 5 * 5, 100)
    #torch.nn.ReLU(),
    #torch.nn.Linear(100, 3),
    #torch.nn.ReLU(),
    #torch.nn.Softmax(dim=1)

  
)


train_Y = torch.from_numpy(np.array(train_Y))
print(type(train_X))
print(type(train_Y))


num_epoch = 100

loss_function = torch.nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)

for epoch in range(num_epoch):
    input = Variable(train_X)
    target = Variable(train_Y)

    #input= torch.reshape(input, (input.shape[0], input.shape[1]))

    # forward
    out = model(input)
    print("out.shape--> ", out.shape)
    #print("xxx -> ",out.shape)
    loss = loss_function(out, target)

    # backward
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # show
    print('Epoch[{}/{}], loss: {:.6f}'
          .format(epoch + 1, num_epoch, loss.data.item()))