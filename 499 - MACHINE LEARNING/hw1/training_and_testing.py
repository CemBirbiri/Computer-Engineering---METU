# -*- coding: utf-8 -*-
"""son_hali

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BW5rfzMesg5JaUVCr1Lyif-rjgLtwBcN
"""

#Loading data on Google Colab:
#!wget user.ceng.metu.edu.tr/~artun/ceng499/dataset.zip
#!unzip dataset.zip

from torch.utils.data import Dataset, DataLoader
import os
from PIL import Image
import torchvision.transforms as T
import torch


class get_data_test(Dataset):
  def __init__(self, dataset_path, split, transforms):
    images_path = os.path.join(dataset_path, split)
    self.data=[]
    with open(os.path.join(images_path, 'labels.txt'), 'r') as f:
      for line in f:
        image_name=line.split()
        label=0.0
        #print("1- ",images_path)
        #print("2.1- ",image_name)
        #print("2.2- ",type(image_name[0]))
        #print("2.3- ",image_name[0][0])
        image_name= image_name[0]
        #print("3- ",image_name)
        image_path = os.path.join(images_path, image_name)
        label=int(label)
        self.data.append((image_path, label))
    self.transforms = transforms

  def __len__(self):
    return len(self.data)
  def __getitem__(self, index):
    image_path = self.data[index][0]
    label = self.data[index][1]
    image=Image.open(image_path)
    image = self.transforms(image)
    return image, label


class get_data(Dataset):
  def __init__(self, dataset_path, split, transforms):
    images_path = os.path.join(dataset_path, split)
    self.data=[]
    with open(os.path.join(images_path, 'labels.txt'), 'r') as f:
      for line in f:
        image_name,label=line.split()
        #print("1--",images_path)
        #print("2--",image_name)
        image_path = os.path.join(images_path, image_name)
        label=int(label)
        self.data.append((image_path, label))
    self.transforms = transforms

  def __len__(self):
    return len(self.data)
  def __getitem__(self, index):
    image_path = self.data[index][0]
    label = self.data[index][1]
    image=Image.open(image_path)
    image = self.transforms(image)
    return image, label

import torch.nn as nn
import torch
import torch.nn.functional as F

class MyModel(nn.Module):
  def __init__(self):
    super(MyModel, self).__init__()
    #self.fc1 == nn.Linear(2048,100) #use this when there is only one layer in the network
    
    
    #self.fc1 == nn.Linear(2048,256) #only for two layer network
    #self.fc2 = nn.Linear(256,100)

    #self.fc1 == nn.Linear(2048,512) #only for two layer network
    #self.fc2 = nn.Linear(512,100)

    #self.fc1 == nn.Linear(2048,1024) #only for two layer network
    #self.fc2 = nn.Linear(1024,100)



    #self.fc1 = nn.Linear(2048 , 1024) #only for three layer network
    #self.fc2 = nn.Linear(1024,256)
    #self.fc3 = nn.Linear(256,100)

    self.fc1 = nn.Linear(2048 , 1024) #only for three layer network
    self.fc2 = nn.Linear(1024,512)
    self.fc3 = nn.Linear(512,100)


    
  
  def forward(self, x):
    #print("1- x.size()) = ",x.size())
    x = x.view(x.size(0),-1)
    #print("2- x.size()) = ",x.size())
    x = self.fc1(x)
    #x = torch.tanh(x)
    #x = F.relu(x)
    x = torch.sigmoid(x)
    x= self.fc2(x)
    #x = torch.tanh(x)
    #x = F.relu(x)
    x = torch.sigmoid(x)
    x = self.fc3(x)
    x = torch.log_softmax(x, dim=1)
    return x



import torch.nn.functional as F 
from sklearn.metrics import accuracy_score
import numpy as np
from torch.autograd import Variable

def should_stop(val_losses, loss_val):
  if len(val_losses)< 15:
    return 0
  else:
    count=0
    
    if val_losses[-1] < loss_val:
      count=count+1
    if val_losses[-2] < loss_val:
      count=count+1
    if val_losses[-3] < loss_val:
      count=count+1
    if val_losses[-4] < loss_val:
      count=count+1
    if val_losses[-5] < loss_val:
      count=count+1
    if val_losses[-6] < loss_val:
      count=count+1
    if val_losses[-7] < loss_val:
      count=count+1
    if val_losses[-8] < loss_val:
      count=count+1
    if val_losses[-9] < loss_val:
      count=count+1
    if val_losses[-10] < loss_val:
      count=count+1
    if val_losses[-11] < loss_val:
      count=count+1
    if val_losses[-12] < loss_val:
      count=count+1
    if val_losses[-13] < loss_val:
      count=count+1
    if val_losses[-14] < loss_val:
      count=count+1
    if val_losses[-15] < loss_val:
      count=count+1
    

    
    if count >=15:
      return 1
    else:
      return 0
      


def train(model, optimizer, train_dataloader, epochs, device, train_losses, val_dataloader,val_losses, val_images, val_labels):
  model.train()
  print(optimizer)
  print(model)
  print("TRAINNING STARS...")
  for epoch_idx in range(epochs):
    temp=[]
    
    for images, labels in train_dataloader:
      
      optimizer.zero_grad()
      pred= model(images)
      loss_train = F.nll_loss(pred, labels)
      loss_train.backward()
      optimizer.step()
      #print("--> ",loss_train.item())

      temp.append(loss_train)
    
    train_losses.append( sum(temp)/len(temp)) #add the avg training loss to visualize
    pred_val = model(val_images)
    loss_val = F.nll_loss(pred_val, val_labels)
    print("training epoch -> ",epoch_idx, loss_val, len(val_losses))
    if should_stop(val_losses, loss_val)==1:
      break
    else:
      val_losses.append(loss_val)
    #val_losses.append(loss_val)
  return train_losses, val_losses

      


def main():
  use_cude= False
  device = torch.device('cuda' if use_cude else 'cpu')
  epochs=100
  torch.manual_seed(123)
  transforms= T.Compose([
                         T.ToTensor(),
                         T.Normalize((0.5, ), (0.5, )),
  ])
  #get the trainig dataset(this one also includes validation dataset)
  whole_dataset = get_data("/content/data", 'train', transforms)

  #get the testing dataset
  test_dataset = get_data_test("/content/data", 'test', transforms)


  #divide training data into validation and training
  train_size = int(0.8 * len(whole_dataset))
  val_size = len(whole_dataset) - train_size
  train_dataset, val_dataset = torch.utils.data.random_split(whole_dataset, [train_size, val_size])

  #dataloaders
  train_dataloader = DataLoader(train_dataset, batch_size= 64, shuffle= True, num_workers=0)
  val_dataloader = DataLoader(val_dataset, batch_size= 2000, shuffle= True, num_workers=0)
  test_dataloader = DataLoader(test_dataset, batch_size= 10000, shuffle= False, num_workers=0)
  
  model = MyModel()
  #model= model.to(device)
  
  #optimizers
  #optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
  #optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

  #these are lists where I keep val and traninng losses to visualize in the graph
  val_losses= []
  train_losses=[]

  #get validation images and labels
  dataiter = iter(val_dataloader)
  val_images, val_labels = dataiter.next()

  #Training phase
  train_losses, val_losses = train(model, optimizer, train_dataloader, epochs, device, train_losses, val_dataloader,val_losses, val_images, val_labels)


  #validation prediction 
  outputs_val = model(val_images)
  _, predicted_val = torch.max(outputs_val, 1)
  print(accuracy_score(val_labels, predicted_val))    


  #print("val_labels = ",val_labels[0:10])
  #print("predicted = ",predicted[0:10])
  #######################################################
  
  # testing phase
  dataiter = iter(test_dataloader)
  test_images, test_labels = dataiter.next()

  outputs_test = model(test_images)
  _, predicted_test = torch.max(outputs_test, 1)
  print(len(predicted_test))
  print(predicted_test[0:15])

  #writing test results to a file
  file1= open('/content/test_labels.txt', "w+")
  for i in range(0,len(predicted_test)):
    file1.writelines(str(i)+ ".png ")
    temp = str(predicted_test[i])
    temp = temp[7:-1]
    file1.writelines(temp)
    file1.writelines("\n")

  file1.close()

  return train_losses, val_losses
if __name__== '__main__':
  train_losses, val_losses = main()

import matplotlib.pyplot as plt

# visualize the training and validation losses
plt.plot(train_losses, label='Training loss')
plt.plot(val_losses, label='Validation loss')
plt.legend()
plt.show()